{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression\n",
    "\n",
    "© Data Trainers LLC. GPL v 3.0.\n",
    "\n",
    "Author: Axel Sirota"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"learning-objectives\"></a>\n",
    "### Learning Objectives\n",
    "- Learn how to perform logistic regression in scikit-learn.\n",
    "- Understand the concepts of probability, odds, e, log, and log-odds in relation to machine learning.\n",
    "- Explain how logistic regression works.\n",
    "- Interpret logistic regression coefficients.\n",
    "- Use logistic regression with categorical features.\n",
    "- Utilize different metrics for evaluating classifier models.\n",
    "- Construct a confusion matrix based on predicted classes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"refresher-fitting-and-visualizing-a-linear-regression-using-scikit-learn\"></a>\n",
    "## Loading the data\n",
    "---\n",
    "\n",
    "Use Pandas to load in the glass attribute data from the UCI machine learning website. The columns are different measurements of properties of glass that can be used to identify the glass type. For detailed information on the columns in this data set: http://archive.ics.uci.edu/ml/datasets/glass+identification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Glass identification data set\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, model_selection, metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "%%writefile get_data.sh\n",
    "mkdir -p data\n",
    "if [ ! -f data/admissions.csv ]; then\n",
    "  wget -O data/admissions.csv https://www.dropbox.com/scl/fi/bjcutl89xibf3r99yc8q0/admissions.csv?rlkey=n36lo0iffob0j73rys1vf3cn5&dl=0\n",
    "fi\n",
    "if [ ! -f data/bank.csv ]; then\n",
    "  wget -O data/bank.csv https://www.dropbox.com/scl/fi/ukxqbfalj3rx5nyzven9j/bank.csv?rlkey=hfrax97bwt45dq9ag0jdpsgsp&dl=0\n",
    "fi\n",
    "if [ ! -f data/evergreen_sites.tsv ]; then\n",
    "  wget -O data/evergreen_sites.tsv https://www.dropbox.com/scl/fi/c310bmln3pv8vdlbweo1k/evergreen_sites.tsv?rlkey=kie6jqkr4klw26b9gnowinyd9&dl=0\n",
    "fi\n",
    "if [ ! -f data/glass.csv ]; then\n",
    "  wget -O data/glass.csv https://www.dropbox.com/scl/fi/dv522a61am4dsc3vkfp4p/glass.csv?rlkey=6l9v685sw98plzj2myvtjpes6&dl=0\n",
    "fi\n",
    "if [ ! -f data/titanic.csv ]; then\n",
    "  wget -O data/titanic.csv https://www.dropbox.com/scl/fi/csnl3vpbq94i4vxpfoe2w/titanic.csv?rlkey=6q576c7lp0e25tb5khvz066l9&dl=0\n",
    "fi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!bash get_data.sh"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "glass = pd.read_csv('data/glass.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# change columns to something more uniform\n",
    "glass.columns = ['ri','na','mg','al','si','k','ca','ba','fe','glass_type']\n",
    "glass.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Data Dictionary**\n",
    "\n",
    "- `Id`: number: 1 to 214\n",
    "- `RI`: refractive index  \n",
    "- `Na`: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10)\n",
    "- `Mg`: Magnesium\n",
    "- `Al`: Aluminum\n",
    "- `Si`: Silicon\n",
    "- `K` : Potassium\n",
    "- `Ca`: Calcium\n",
    "- `Ba`: Barium\n",
    "- `Fe`: Iron\n",
    "- `Type` : Type of glass:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Pretend we want to predict `ri`, and our only feature is `al`. How could we do it using machine learning?**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set(font_scale=1.5);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#scatter with regression line\n",
    "sns.lmplot(x='al', y='ri', data=glass)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"predicting-a-categorical-response\"></a>\n",
    "## Predicting a Single Categorical Response\n",
    "---\n",
    "\n",
    "Linear regression is appropriate when we want to predict the value of a continuous target/response variable, but what about when we want to predict membership in a class or category?\n",
    "\n",
    "**Examine the glass type column in the data set. What are the counts in each category?**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Examine glass_type.\n",
    "glass.glass_type.value_counts().sort_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Say these types are subdivisions of broader glass types:\n",
    "\n",
    "> **Window glass:** types 1, 2, and 3\n",
    "\n",
    "> **Household glass:** types 5, 6, and 7\n",
    "\n",
    "**Create a new `household` column that indicates whether or not a row is household glass, coded as 1 or 0, respectively.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Types 1, 2, 3 are window glass.\n",
    "# Types 5, 6, 7 are household glass.\n",
    "glass.tail()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "glass.household.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "glass.household.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "glass['household_text'] = None\n",
    "glass.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's change our task, so that we're predicting the `household` category using `al`. Let's visualize the relationship to figure out how to do this.\n",
    "\n",
    "**Make a scatter plot comparing `al` and `household`.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(glass.al, glass.household)\n",
    "plt.xlabel('al')\n",
    "plt.ylabel('household')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Fit a new `LinearRegression` predicting `household` from `al`.**\n",
    "\n",
    "Let's draw a regression line like we did before:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fit a linear regression model and store the predictions.\n",
    "feature_cols = ['al']\n",
    "X = glass[feature_cols]\n",
    "y = glass.household\n",
    "lr = LinearRegression()\n",
    "lr.fit(X,y)\n",
    "# Fit the model\n",
    "glass['household_pred'] = lr.predict(X) # prediction via Lin Reg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Scatter plot that includes the regression line\n",
    "plt.scatter(glass.al, glass.household)\n",
    "plt.plot(glass.al, glass.household_pred, color='red')\n",
    "plt.xlabel('al')\n",
    "plt.ylabel('household')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If **al=3**, what class do we predict for household? **1**\n",
    "\n",
    "If **al=1.5**, what class do we predict for household? **0**\n",
    "\n",
    "We predict the 0 class for **lower** values of al, and the 1 class for **higher** values of al. What's our cutoff value? Around **al=2**, because that's where the linear regression line crosses the midpoint between predicting class 0 and class 1.\n",
    "\n",
    "Therefore, we'll say that if **household_pred >= 0.5**, we predict a class of **1**, else we predict a class of **0**."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Using this threshold, create a new column of our predictions for whether a row is household glass.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Understanding np.where\n",
    "import numpy as np\n",
    "\n",
    "# Transform household_pred to 1 or 0.\n",
    "glass['household_pred_class'] = np.where(glass.household_pred >= 0.5, 1, 0)\n",
    "glass.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Plot a line that shows our predictions for class membership in household vs. not.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sort so we can have a continuous line\n",
    "glass.sort_values('al', inplace=True)\n",
    "# Plot the class predictions.\n",
    "plt.scatter(glass.al, glass.household)\n",
    "\n",
    "plt.xlabel('al')\n",
    "plt.ylabel('household')\n",
    "\n",
    "plt.plot(glass.al, glass.household_pred_class, color='red')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"using-logistic-regression-for-classification\"></a>\n",
    "## Using Logistic Regression for Classification\n",
    "---\n",
    "\n",
    "Logistic regression is a more appropriate method for what we just did with a linear regression. The values output from a linear regression cannot be interpreted as probabilities of class membership since their values can be greater than 1 and less than 0. Logistic regression, on the other hand, ensures that the values output as predictions can be interpreted as probabilities of class membership.\n",
    "\n",
    "**Import the `LogisticRegression` class from `linear_model` below and fit the same regression model predicting `household` from `al`.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fit a logistic regression model and store the class predictions.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "feature_cols = ['al']\n",
    "X = glass[feature_cols]\n",
    "y = glass.household\n",
    "\n",
    "logreg.fit(X,y)\n",
    "pred = logreg.predict(X)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Plot the predicted class using the logistic regression as we did for the linear regression predictions above.**\n",
    "\n",
    "As you can see, the class predictions are the same."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the class predictions.\n",
    "plt.scatter(glass.al, glass.household)\n",
    "plt.plot(glass.al, pred, color='red')\n",
    "plt.xlabel('al')\n",
    "plt.ylabel('household')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What if we wanted the predicted probabilities instead of just the class predictions, to understand how confident we are in a given prediction?\n",
    "\n",
    "**Using the built-in `.predict_proba()` function, examine the predicted probabilities for the first handful of rows of `X`.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logreg.predict_proba(X)[0:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sklearn orders the columns according to our class labels. The two-column output of `predict_proba` returns a column for each class of our `household` variable. The first column is the probability of `household=0` for a given row, and the second column is the probability of `household=1`.\n",
    "\n",
    "**Store the predicted probabilities of class=1 in its own column in the data set.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Store the predicted probabilities of class 1.\n",
    "glass['household_pred_prob'] = logreg.predict_proba(X)[:, 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "glass.sample(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Plot the predicted probabilities as a line on our plot (probability of `household=1` as `al` changes).**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the predicted probabilities.\n",
    "plt.scatter(glass.al, glass.household)\n",
    "plt.plot(glass.al, glass.household_pred_prob, color='red')\n",
    "plt.xlabel('al')\n",
    "plt.ylabel('probability of household')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Examine some example predictions.\n",
    "print(logreg.predict_proba([[1]]))\n",
    "print(logreg.predict_proba([[2]]))\n",
    "print(logreg.predict_proba([[3]]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hands on Excercise\n",
    "<img src=\"https://www.dropbox.com/scl/fi/qt7g1wgsnpne43cfwumu0/hands_on.jpg?rlkey=q1zyeuoiuvofnzux4iylfo6ax&raw=1\" width=\"100\" height=\"100\" align=\"right\"/>\n",
    "\n",
    "- Select 2 different features\n",
    "- y will remain the same `glass.household`\n",
    "- Evaluate the model with `model.score` on the testing data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fill the exercise!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"comparing-logistic-regression-to-other-models\"></a>\n",
    "## Comparing Logistic Regression to Other Models\n",
    "---\n",
    "\n",
    "Advantages of logistic regression:\n",
    "\n",
    "- Highly interpretable (if you remember how).\n",
    "- Model training and prediction are fast.\n",
    "- No tuning is required (excluding regularization).\n",
    "- Features don't need scaling.\n",
    "- Can perform well with a small number of observations.\n",
    "- Outputs well-calibrated predicted probabilities.\n",
    "\n",
    "Disadvantages of logistic regression:\n",
    "\n",
    "- Presumes a linear relationship between the features and the log odds of the response.\n",
    "- Performance is (generally) not competitive with the best supervised learning methods.\n",
    "- Can't automatically learn feature interactions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "----\n",
    "\n",
    "## Is accuracy is good metric?\n",
    "<img src=\"https://www.dropbox.com/scl/fi/ppmtzavh3ot6jinkb35vd/accuracy.png?rlkey=32gfvubdwn1p4i9anwut7ug39&raw=1\" align=\"center\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The Accuracy Paradox\n",
    "\n",
    "Accuracy is a very intuitive metric — it's a lot like an exam score where you get total correct/total attempted. However, accuracy is often a poor metric in application. There are many reasons for this:\n",
    "- Imbalanced problems problems with 95% positives in the baseline will have 95% accuracy even with no predictive power.\n",
    "  - This is the paradox; pursuing accuracy often means predicting the most common class rather than doing the most useful work.\n",
    "- Applications often have uneven penalties and rewards for true positives and false positives.\n",
    "- Ranking predictions in the correct order be more important than getting them correct.\n",
    "- In many case we need to know the exact probability of a positives and negatives.\n",
    "  - To calculate an expected return.\n",
    "  - To triage observations that are borderline positive."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"advanced-classification-metrics\"></a>\n",
    "## Advanced Classification Metrics\n",
    "\n",
    "---\n",
    "\n",
    "When we evaluate the performance of a logistic regression (or any classifier model), the standard metric to use is accuracy: How many class labels did we guess correctly? However, accuracy is only one of several metrics we could use when evaluating a classification model.\n",
    "\n",
    "$$Accuracy = \\frac{total~predicted~correct}{total~predicted}$$\n",
    "\n",
    "Accuracy alone doesn’t always give us a full picture.\n",
    "\n",
    "If we know a model is 75% accurate, it doesn’t provide any insight into why the 25% was wrong."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Consider a binary classification problem where we have 165 observations/rows of people who are either smokers or nonsmokers.\n",
    "\n",
    "<table style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are 60 in class 0, nonsmokers, and 105 observations in class 1, smokers\n",
    "<table style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\">60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\">105</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have 55 predictions of class, predicted as nonsmokers, and 110 of class 1, predicted to be smokers.\n",
    "\n",
    "<table style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\">60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\">105</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\">55</td>\n",
    "    <td style=\"text-align: center\">110</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- **True positives (TP):** These are cases in which we predicted yes (smokers), and they actually are smokers.\n",
    "- **True negatives (TN):** We predicted no, and they are nonsmokers.\n",
    "- **False positives (FP):** We predicted yes, but they were not actually smokers. (This is also known as a \"Type I error.\")\n",
    "- **False negatives (FN):** We predicted no, but they are smokers. (This is also known as a \"Type II error.\")\n",
    "<table style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center\">TN = 50</td>\n",
    "    <td style=\"text-align: center\">FP = 10</td>\n",
    "    <td style=\"text-align: center\">60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\">FN = 5</td>\n",
    "    <td style=\"text-align: center\">TP = 100</td>\n",
    "    <td style=\"text-align: center\">105</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\">55</td>\n",
    "    <td style=\"text-align: center\">110</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Categorize these as TP, TN, FP, or FN:**\n",
    "\n",
    "Try not to look at the answers above.\n",
    "    \n",
    "- We predict nonsmoker, but the person is a smoker.\n",
    "- We predict nonsmoker, and the person is a nonsmoker.\n",
    "- We predict smoker and the person is a smoker.\n",
    "- We predict smoker and the person is a nonsmoker.\n",
    "\n",
    "<!--ANSWER\n",
    "- FN\n",
    "- TN\n",
    "- TP\n",
    "- FP\n",
    "-->"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"accuracy-true-positive-rate-and-false-negative-rate\"></a>\n",
    "### Accuracy, True Positive Rate, and False Negative Rate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Accuracy:** Overall, how often is the classifier correct?\n",
    "\n",
    "<span>\n",
    "    (<span style=\"color: green\">TP</span>+<span style=\"color: red\">TN</span>)/<span style=\"color: blue\">total</span> = (<span style=\"color: green\">100</span>+<span style=\"color: red\">50</span>)/<span style=\"color: blue\">165</span> = 0.91\n",
    "</span>\n",
    "\n",
    "<table style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom; color: blue\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center; background-color: red\">TN = 50</td>\n",
    "    <td style=\"text-align: center\">FP = 10</td>\n",
    "    <td style=\"text-align: center\">60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\">FN = 5</td>\n",
    "    <td style=\"text-align: center; background-color: green\">TP = 100</td>\n",
    "    <td style=\"text-align: center\">105</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\">55</td>\n",
    "    <td style=\"text-align: center\">110</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**True positive rate (TPR)** asks, “Out of all of the target class labels, how many were accurately predicted to belong to that class?”\n",
    "\n",
    "For example, given a medical exam that tests for cancer, how often does it correctly identify patients with cancer?\n",
    "\n",
    "<span>\n",
    "<span style=\"color: green\">TP</span>/<span style=\"color: blue\">actual yes</span> = <span style=\"color: green\">100</span>/<span style=\"color: blue\">105</span> = 0.95\n",
    "</span>\n",
    "\n",
    "<table style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center\">TN = 50</td>\n",
    "    <td style=\"text-align: center\">FP = 10</td>\n",
    "    <td style=\"text-align: center\">60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\">FN = 5</td>\n",
    "    <td style=\"text-align: center;background-color: green\">TP = 100</td>\n",
    "    <td style=\"text-align: center;color: blue\">105</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\">55</td>\n",
    "    <td style=\"text-align: center\">110</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**False positive rate (FPR)** asks, “Out of all items not belonging to a class label, how many were predicted as belonging to that target class label?”\n",
    "\n",
    "For example, given a medical exam that tests for cancer, how often does it trigger a “false alarm” by incorrectly saying a patient has cancer?\n",
    "\n",
    "<span>\n",
    "<span style=\"color: orange\">FP</span>/<span style=\"color: blue\">actual no</span> = <span style=\"color: orange\">10</span>/<span style=\"color: blue\">60</span> = 0.17\n",
    "</span>\n",
    "\n",
    "<table style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center\">TN = 50</td>\n",
    "    <td style=\"text-align: center;background-color: orange\">FP = 10</td>\n",
    "    <td style=\"text-align: center;color:blue\">60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\">FN = 5</td>\n",
    "    <td style=\"text-align: center\">TP = 100</td>\n",
    "    <td style=\"text-align: center\">105</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\">55</td>\n",
    "    <td style=\"text-align: center\">110</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Can you see that we might weigh TPR AND FPR differently depending on the situation?**\n",
    "\n",
    "- Give an example when we care about TPR, but not FPR.\n",
    "- Give an example when we care about FPR, but not TPR.\n",
    "\n",
    "<!--\n",
    "ANSWER:\n",
    "- During an initial medical diagnosis, we want to be sensitive. We want initial screens to come up with a lot of true positives, even if we get a lot of false positives.\n",
    "- If we are doing spam detection, we want to be precise. Anything that we remove from an inbox must be spam, which may mean accepting fewer true positives.\n",
    "-->"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Confusion Matrix\n",
    "<img src=\"https://www.dropbox.com/scl/fi/eaig0g63lct0r7dzt6qit/confusion.png?rlkey=edw4kjneymt6q0hl6r48512py&raw=1\" align=\"center\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# What is precison and recall?\n",
    "<img src=\"https://www.dropbox.com/scl/fi/yf2rcxzstnz6p4ef11xj0/recall.png?rlkey=mmbfwbgvzadrwpgqwi44gxhnk&raw=1\"  align=\"center\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lets review the Matrix for above example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lesson Review\n",
    "- **Logistic regression**\n",
    "  - What kind of machine learning problems does logistic regression address?\n",
    "  - What do the coefficients in a logistic regression represent? How does the interpretation differ from ordinary least squares? How is it similar?\n",
    "  \n",
    "- **The confusion matrix**\n",
    "  - How do true positive rate and false positive rate help explain accuracy?\n",
    "  - Why might one classification metric be more important to tune than another? Give an example of a business problem or project where this would be the case."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now you do it\n",
    "\n",
    "Predicted who gets admitted or not?\n",
    "\n",
    ">  test_size : 0.25   and random_state = 99\n",
    "\n",
    "<img src=\"https://www.dropbox.com/scl/fi/qt7g1wgsnpne43cfwumu0/hands_on.jpg?rlkey=q1zyeuoiuvofnzux4iylfo6ax&raw=1\" width=\"100\" height=\"100\" align=\"right\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Below we will load in some data on admissions to college.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model, model_selection, metrics\n",
    "\n",
    "admissions = pd.read_csv('data/admissions.csv')\n",
    "admissions.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "admissions.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "admissions.dropna(inplace=True)\n",
    "admissions.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}